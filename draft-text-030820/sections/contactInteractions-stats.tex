\section{Statistical Analysis}\label{sec:ciStat}

Statistical methods are used to distill two types of information from the collected dataset.
First, what is the probability that the observed data is incompatible with the background-only hypothesis.
Second, what is smallest putative signal such that, if extant, would produce a signal+background hypothesis that is incompatible with the observed data.
The former is answered by a significance test, described in Section \ref{sec:ciSigTest}, while the latter is answered by setting a limit, described in Section \ref{sec:ciLimitSetting}.

\subsection{Likelihood Ratio and CLs Method}


\begin{figure}[h!]
\captionsetup[subfigure]{position=b}
\centering
\includegraphics[width=0.5\textwidth]{figures/ci/profileLikelihoodPlots/toys-n29-fc-lambda-ll-const-LL-nToy5000-nSteps50-seed8.png}
\caption{}
\label{fig:ciClsProfileLikelihood}
\end{figure}

% Test statistic: likelihood ratio
The fundamental tool used to compare two hypotheses is the \emph{test statistic}.
While this can be any quantity calculated from data, an optimal choice for the test statistic may be made to best resolve the difference between the two hypotheses.
The Neyman-Person lemma states that the likelihood ratio test is the most likely to reject the null hypotheses given the alternate hypotheses is true.
The likelihood ratio is defined:
\begin{equation}\begin{split}\label{eqn:ciLikelihoodTestStat}
\Lambda(N_\text{obs})=\frac{\mathcal{L}(N_\text{obs}|\theta_1)}{\mathcal{L}(N_\text{obs}|\theta_0)},
\end{split}\end{equation} 
where $\mathcal{L}(N_\text{obs}|\theta_0)$ and $\mathcal{L}(N_\text{obs}|\theta_1)$ are the likelihoods to observe data $N_\text{obs}$ under the null and alternate hypotheses, respectively.
These are complicated functions, the practical forms of the likelihoods are given in Section \ref{sec:ciStatModel}.
Data measured at larger values of $\Lambda(N_\text{obs})$ are \emph{less compatible} with the background-only hypothesis.
In practice, the quantity $-\ln{\Lambda(N_\text{obs})}$ is used for computational simplicity.
An example if the distributions of $-\ln{\Lambda(N_\text{obs})}$ under the null (background) and alternative (S+B) hypotheses are shown in Figure \ref{fig:ciClsProfileLikelihood}.

\begin{figure}[h!]
\captionsetup[subfigure]{position=b}
\centering
\includegraphics[width=0.5\textwidth]{figures/ci/cls.png}
\caption{}
\label{fig:ciCls}
\end{figure}

% CLs
The PDF of $\Lambda(N_\text{obs})$ is defined under both the null and alternate hypotheses.
Taking first the PDF under the null hypothesis, $\Lambda_0(N_\text{obs})$.
The integral of the test statistic $\Lambda_0(N_\text{obs})$ above a given observed value of $N_\text{obs}$, $x_\text{obs}$, defines the \emph{p-value} $p_0$ of the observation.
This is the probability to observe a value of $N_\text{obs}$ that is \emph{less} compatible with the null hypothesis than the observed value.
The complement of the p-value, calculated under the null hypothesis, defines the value $\clb\equiv1-p_0$.
An analogous value, $\clsb$, is defined for the likelihood ratio under the alternative hypothesis, $\Lambda_1(N_\text{obs})$.
For a measured $x_\text{obs}$, $p_1$ is the integral of $\Lambda_1(N_\text{obs})$ above that point, and $\clsb\equiv1-p_1$
Finally the ratio of these two values defines the arbitrarily named value $\cls\equiv \clsb/\clb$.
This ratio describes the \emph{approximate} confidence in the alternate hypothesis.\cite{read}
This is a desirable feature, since the \cls ratio actually offers a comparative confidence in the alternative hypothesis relative to the null hypothesis.


\subsection{Statistical Model}\label{sec:ciStatModel}

Each statistical question is answered through the comparison of null and alternate hypotheses.
Three related tests are performed:
\begin{enumerate}
    \item The background-only hypothesis vs a generic model-independent hypothesis of signal events.
    \item The background-only hypothesis vs a contact interaction hypothesis involving either lepton channel.
    \item The background-only hypothesis vs a contact interaction hypothesis involving both lepton channels.
\end{enumerate}
Each of these hypotheses are described by one of the following likelihood functions.
The likelihood converts the hypothesis into an expression of the probability to observe a yield in a SR.
In each case, a \emph{parameter of interest} (POI) is used to define the signal hypothesis.
For the model-independent hypothesis of a generic signal production, the POI is simply the number of signal events produced in the SR, $N_s$.
For the contact interaction model, the POI is the energy scale \lam. Different values of \lam correspond to different alternative hypotheses.
Figure \ref{fig:ciNSigInSr} shows that, in the case of CI models, the number of signal events produced is a function of \lam: $N_s(\lam)$.
Comparisons of the model-independent results with the CI results provides a useful cross-check.

The first likelihoods describe the background-only hypothesis and a hypothesis predicting some number of signal events, $N_s$, to be reconstructed in the SR.
In this model, the POI is $N_s$.
The PDFs of the number of events to observe in the SR for each hypothesis are given in Equations \ref{eqn:ciNullLikelihoodNSig} and \ref{eqn:ciAltLikelihoodNSig}.
\begin{flalign}
\text{PDF}_\text{b}(\vec{\theta}) =& \text{Pois}((1+\theta_\text{b})\times N_b) \times \text{Gaus}(\theta_\text{b},\sigma_\text{b}) \label{eqn:ciNullLikelihoodNSig}\\
\text{PDF}_\text{s+b}(\vec{\theta}) =& \text{Pois}(N_s+(1+\theta_\text{b})\times N_b) \times \text{Gaus}(\theta_\text{b},\sigma_\text{b}) \label{eqn:ciAltLikelihoodNSig}
\end{flalign}
The functions $\text{Pois}(N_\text{exp})$ are Poisson probability distributions with medians $N_\text{exp}$.
In this case, $N_\text{exp}=(1+\theta_\text{b})\times N_b$, where $N_b$ is the expected background in the SR from the extrapolation procedure.
The parameter $\theta_\text{b}$ is a nuisance parameter that is fit to the data, and corresponds to the measured uncertainty on $N_b$.
The functions $\text{Gaus}(\theta_\text{b},\sigma_\text{b})$ are Gaussian constraints on the nuisance parameter $\theta_\text{b}$. These have means centered at $\theta_\text{b}=0$, and standard deviations $\sigma_\text{b}$.
For these PDFs, which are constructed to be agnostic as to the form of the signal model, the uncertainty $\sigma_\text{b}$ is the sum in quadrature of the extrapolation uncertainty and the ISS.

Next are the PDFs for hypotheses describing contact interactions, limited to individual lepton channels.
Equations \ref{eqn:ciNullLikelihood} and \ref{eqn:ciAltLikelihood} give the probability distributions for null and alternative hypotheses, respectively.
\begin{flalign}
\text{PDF}_\text{b}(\vec{\theta}) =& \text{Pois}((1+\theta_\text{b})\times N_b) \times \text{Gaus}(\theta_\text{b},\sigma_\text{b}) \label{eqn:ciNullLikelihood}\\
\text{PDF}_\text{s+b}(\vec{\theta}) =& \text{Pois}((1+\theta_\text{s})\times N_s(\Lambda)+(1+\theta_\text{b})\times N_b) \times \notag \\
                                          & \text{Gaus}(\theta_\text{b},\sigma_\text{b}) \times \text{Gaus}(\theta_\text{s},\sigma_\text{s}) \label{eqn:ciAltLikelihood}
\end{flalign}
The standard deviations of the Gaussian constraints correspond to the uncertainties described in Section \ref{sec:ciSyst}. 
$\sigma_\text{s}$ is the experimental uncertainty on the signal yield.
$\sigma_\text{b}$ is the total uncertainty on the background yield, which consists of the sum in quadrature of the extrapolation, ISS, and the function bias uncertainties.
Each of these numbers is given in Table \ref{tab:ciUncerts}.
The nuisance parameters are seen to modify the signal and background expectations in the Poisson function via $(1+\theta)$ terms.
In these models, the parameter of interest, \lam, is used to determine the number of signal events expected in the SR.
This is performed with a smooth interpolation between the generated CI shapes to provide $N_s(\lam)$.
For each of the four signal, a set of PDFs is constructed for each chirality combination, leading to 16 total models.

Last are the hypotheses dealing with CI models in both lepton channels.
These hypotheses predict signal production in both \ee and \mm channels.
For each constructive or destructive SRs, the observations in both \ee and \mm SRs are mutually independent.
Therefore the combined likelihood is the product of the individual likelihoods for each lepton channel corresponding to Equations \ref{eqn:ciNullLikelihood} and \ref{eqn:ciAltLikelihood}.
The observations in the constructive and destructive SRs of the same lepton channel are not mutually independent, and therefore are not combined.
Consequently, for each interference pattern, the likelihoods of observations in the two leptonic SRs are combined to produce a total likelihood.
This is repeated for each chirality, resulting in eight pairs of hypotheses.

For each null and alternate ($\text{PDF}_\text{b}$ or $\text{PDF}_\text{s+b}$) PDF given here, a corresponding likelihood ($\mathcal{L}(N_\text{obs}|\theta_0)$ or $\mathcal{L}(N_\text{obs}|\theta_1)$) exists.
In this form, the likelihood expresses the probability to observe $N_\text{obs}$ events given some nuisance parameters $\theta$.

% Frequintist throw toys
It is helpful in computing \cls values to have PDF shapes, under both null and alternative hypotheses, for the likelihood ratio test statistic given in Equation \ref{eqn:ciLikelihoodTestStat}.
The shape of the PDF is determined straightforwardly from the null and alternate PDF shapes with a frequentist Monte-Carlo procedure.
A number of pseudo-observations are generated from each hypothesis PDF ($\text{PDF}_\text{b}$ or $\text{PDF}_\text{s+b}$).
The nuisance parameters are allowed to vary corresponding to the width of their corresponding Gaussian constraint.
The number of observed events is sampled from the Poisson term.

The test statistic is calculated for each pseudo-observation.
This is simply a matter of fitting nuisance parameters of the appropriate likelihood ($\mathcal{L}(N_\text{obs}|\theta_0)$ or $\mathcal{L}(N_\text{obs}|\theta_1)$) to the pseudo-observation, and noting the probability of that observation.
This leads to distributions of the test statistic under each hypothesis, as shown in Figure \ref{fig:ciClsProfileLikelihood}.

\subsection{Significance test}\label{sec:ciSigTest}

\begin{figure}[h!]
\captionsetup[subfigure]{position=b}
\centering
\subfloat[][]{{\includegraphics[width=0.24\textwidth]{figures/ci/nEventsTestStat/ee-const.png}}}
\subfloat[][]{{\includegraphics[width=0.24\textwidth]{figures/ci/nEventsTestStat/ee-dest.png}}}
\subfloat[][]{{\includegraphics[width=0.24\textwidth]{figures/ci/nEventsTestStat/mm-const.png}}}
\subfloat[][]{{\includegraphics[width=0.24\textwidth]{figures/ci/nEventsTestStat/mm-dest.png}}}
\caption{}
\label{fig:ciSignificance}
\end{figure}

The significance of the data, given the background-only hypothesis, is tested evaluated by considering the p-value.
While the it is possible to use likelihood test statistic in Equation \ref{eqn:ciLikelihoodTestStat}, the signal signal dependence is undesirable.
Instead, the number of events yielded in the SR, $N_\text{events}$, is used as the test statistic.
The corresponding p-value is the probability of observing a yield at least as large as that seen in data.
Figure \ref{fig:ciSignificance} shows the distributions of the event yields predicted by the background-only hypotheses in each SR.
The observed number of events is illustrated, and the integral corresponding to the p-value is highlighted.

The PDF distributions of $N_\text{events}$ is produced using a frequentist approach.
The shape is approximated with one hundred thousand pseudo-experiments drawn from the null hypothesis likelihood given in Equation \ref{eqn:ciNullLikelihood}.

Probabilities of observations are often cited in terms of standard deviations from the mean with respect to the normal distribution.
The background \emph{significance} of a p-value is defined as the inverse of the cumulative distribution function of the upper tail of the normal (Gaussian) distribution.
This is illustrated for each SR in Figure \ref{fig:ciSignificance}.

\subsection{Limit test}\label{sec:ciLimitSetting}

Limit tests are a generalization of the significance test. %, where a set of signal+background hypotheses are rejected due to their incompatibility with the data.
In this context, the null hypothesis is taken to be the signal+background hypothesis, and the alternative hypothesis is defined as the background-only hypothesis $\text{PDF}_\text{b}$.
The hypothesis test then seeks to reject the signal+background hypothesis in favor of the background-only hypothesis due to their incompatibility with the observed data.
The set of signal+background hypotheses that are considered are described by values of the POI.
For the purpose of this analysis, this means the goal of the limit setting procedure is to find the limiting POI value that predicts the smallest non-rejected signal contribution to the SR.
This is done using a series of hypothesis tests scanned over a range of POI values. \footnote{An animated illustration of these scans may be found: \url{http://hg8i.com/thesis/likelihoods/}.}
This value is reported as the \emph{limit} on the POI.
Values of the POI that predict larger signal contributions to the SR describe excluded signal models, while values of the POI that predict fewer signal events in the SR remain admissible.

The compatibility of hypotheses with respect to the observation is measured using \cls.
The value of \cls plays a similar role as would a p-value.
For a particular value of the POI, if the \cls value exceeds 0.95 then the signal+background hypothesis is considered rejected, and the value of the POI is considered excluded.

There are two types of hyperparameters of the limit setting procedure.
First is the range and resolution of values of to consider in a scan over the POI.
A broader range with finer resolution adds accuracy but also computational expense to the resulting limit.
This reaches a point of diminishing returns when the accuracy of the limit exceeds the second order uncertainties on the systematics.
When the limiting value of the POI falls between steps in the POI scan, an interpolation is made between the steps.
In general, 30 to 50 steps are sufficient for the purpose of the results reported here.

The second type of hyperparameters defines to the number of pseudo-observations, or toys, to calculate the PDF shapes for the test statistic.
The likelihood ratio (Equation \ref{eqn:ciLikelihoodTestStat}) serves as the test statistic for all limit setting.
The reliability of the results is quite sensitive to the number of toys.
Figure \ref{fig:ciClsProfileLikelihood} illustrates this well: many toys are needed in order to smoothly sample the tails of the likelihood distributions.
In this analysis, the limits were found to converge to a relative accuracy of $10^{-2}$ between one and two hundred thousand toys.
This 
For the results final results, four hundred thousand toys were used for each POI step.
